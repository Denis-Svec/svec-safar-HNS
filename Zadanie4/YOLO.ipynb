{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "from pycocotools.coco import COCO\n",
    "from torchvision.io import read_image\n",
    "from torchvision.ops.boxes import masks_to_boxes\n",
    "from torchvision import tv_tensors\n",
    "from torchvision.transforms.v2 import functional as F\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0+cu118\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mat = scipy.io.loadmat('cupDataset.mat')\n",
    "# mat.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['           cupImagename                   cup       \\n',\n",
       " '    ___________________________    _________________\\n',\n",
       " '\\n',\n",
       " \"    {'cup_images\\\\cup(1).jpg'  }    {[147 57 67 105]}\\n\",\n",
       " \"    {'cup_images\\\\cup(10).jpg' }    {[  18 61 48 99]}\\n\",\n",
       " \"    {'cup_images\\\\cup(100).jpg'}    {[ 156 69 58 95]}\\n\",\n",
       " \"    {'cup_images\\\\cup(101).jpg'}    {[ 171 9 53 165]}\\n\",\n",
       " \"    {'cup_images\\\\cup(102).jpg'}    {[  38 88 21 67]}\\n\",\n",
       " \"    {'cup_images\\\\cup(103).jpg'}    {[148 28 72 187]}\\n\",\n",
       " \"    {'cup_images\\\\cup(104).jpg'}    {[  2 51 49 125]}\\n\"]"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'data.txt'\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    data_lines = file.readlines()\n",
    "\n",
    "data_lines[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cupImagename</th>\n",
       "      <th>cup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cup(100).jpg</td>\n",
       "      <td>[156.0, 69.0, 58.0, 95.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cup(101).jpg</td>\n",
       "      <td>[171.0, 9.0, 53.0, 165.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cup(102).jpg</td>\n",
       "      <td>[38.0, 88.0, 21.0, 67.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cup(103).jpg</td>\n",
       "      <td>[148.0, 28.0, 72.0, 187.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cup(104).jpg</td>\n",
       "      <td>[2.0, 51.0, 49.0, 125.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cupImagename                         cup\n",
       "0  cup(100).jpg   [156.0, 69.0, 58.0, 95.0]\n",
       "1  cup(101).jpg   [171.0, 9.0, 53.0, 165.0]\n",
       "2  cup(102).jpg    [38.0, 88.0, 21.0, 67.0]\n",
       "3  cup(103).jpg  [148.0, 28.0, 72.0, 187.0]\n",
       "4  cup(104).jpg    [2.0, 51.0, 49.0, 125.0]"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "def parse_line(line):\n",
    " \n",
    "    match = re.match(r\"\\s*{'(.*?)'}\\s*{\\[(.*?)\\]}\", line)\n",
    "    if match:\n",
    "        image_name = match.group(1)\n",
    "        cup_data = list(map(int, match.group(2).split()))\n",
    "        return {'cupImagename': image_name, 'cup': cup_data}\n",
    "    return None\n",
    "\n",
    "parsed_data = [parse_line(line) for line in data_lines if line.strip() and not line.startswith('cupImagename')]\n",
    "\n",
    "parsed_data = [data for data in parsed_data if data is not None]\n",
    "\n",
    "data = pd.DataFrame(parsed_data)\n",
    "data['cup'] = data['cup'].apply(lambda x: [float(i) for i in x])\n",
    "data['cupImagename'] = data['cupImagename'].str.replace(r'cup_images\\\\', '', regex=True)\n",
    "\n",
    "\n",
    "data.to_excel('data.xlsx')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cupImagename                         cup\n",
      "0  cup(100).jpg   [156.0, 69.0, 58.0, 95.0]\n",
      "1  cup(101).jpg   [171.0, 9.0, 53.0, 165.0]\n",
      "2  cup(102).jpg    [38.0, 88.0, 21.0, 67.0]\n",
      "3  cup(103).jpg  [148.0, 28.0, 72.0, 187.0]\n",
      "4  cup(104).jpg    [2.0, 51.0, 49.0, 125.0]\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "# Function to convert string representation of list to actual list\n",
    "\n",
    "\n",
    "# Optionally, drop the unnamed column if it's just an index\n",
    "if 'Unnamed: 0' in data.columns:\n",
    "    data.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "\n",
    "# Display the modified dataframe\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchvision.transforms import v2 as T\n",
    "# from torchvision import transforms\n",
    "\n",
    "# class CupDataset(Dataset):\n",
    "#     def __init__(self, dataframe, root_dir, transform=None):\n",
    "\n",
    "#         self.dataframe = dataframe\n",
    "#         self.root_dir = root_dir\n",
    "#         self.transform = transform or transforms.Compose([\n",
    "#             transforms.Resize((224, 224)),\n",
    "#             transforms.ToTensor()\n",
    "#         ])\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.dataframe)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         img_name = os.path.join(self.root_dir, self.dataframe.iloc[idx, 0])\n",
    "#         image = Image.open(img_name).convert('RGB')\n",
    "#         orig_width, orig_height = image.size\n",
    "\n",
    "#         image_id = torch.tensor([idx], dtype=torch.int64)\n",
    "#         box = torch.tensor(self.dataframe.iloc[idx, 1], dtype=torch.float32)\n",
    "#         #y_max, x_max, x_min, y_min = box\n",
    "#         #y_max, x_max, y_min,x_min = box\n",
    "#         #x_max, y_max, y_min, x_min = box\n",
    "#         #x_max, y_max, x_min, y_min = box\n",
    "#         #x_min, y_min, x_max, y_max  = box\n",
    "#         # x_max, x_min, y_max, y_min = box\n",
    "#         #y_max, y_min, x_max, x_min = box\n",
    "#         y_max, y_min, x_max, x_min = box\n",
    "\n",
    "\n",
    "#         scale_x = 224.0 / orig_width\n",
    "#         scale_y = 224.0 / orig_height   \n",
    "\n",
    "\n",
    "#         # Format the box for model input\n",
    "#         new_box = torch.tensor([x_min * scale_x, y_min * scale_y, x_max * scale_x, y_max * scale_y], dtype=torch.float32)\n",
    "#         labels = torch.ones((1,), dtype=torch.int64)\n",
    "#         area = (new_box[3] - new_box[1]) * (new_box[2] - new_box[0])\n",
    "\n",
    "#         image =  transforms.Resize((224,224))(image)\n",
    "#         image = transforms.ToTensor()(image)\n",
    "\n",
    "#         # Create target dictionary\n",
    "#         target = {}\n",
    "#         target[\"boxes\"] = new_box\n",
    "#         target[\"labels\"] = labels\n",
    "#         target[\"image_id\"] = image_id\n",
    "#         target[\"area\"] = area\n",
    "\n",
    "#         # if self.transform is not None:\n",
    "#         #     image, target = self.transform(image, target)\n",
    "\n",
    "#         return image, target\n",
    "\n",
    "    \n",
    "# # Define a transform (if necessary)\n",
    "\n",
    "# # def get_transform():\n",
    "# #     transforms = []\n",
    "    \n",
    "# #     transforms.append(T.ToDtype(torch.float, scale=True))\n",
    "# #     transforms.append(T.ToPureTensor())\n",
    "# #     return T.Compose(transforms)\n",
    "\n",
    "# # Instantiate the dataset\n",
    "# cup_dataset = CupDataset(dataframe=data, root_dir='C:/Users/denis/Desktop/HNS/Git/svec-safar-HNS/Zadanie4/cup_images/', transform=None)\n",
    "\n",
    "# # Create a data loader\n",
    "# data_loader = DataLoader(cup_dataset, batch_size=4, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_tensor_image_with_box(tensor_image, box):\n",
    "    # Convert from tensor to numpy\n",
    "    numpy_image = tensor_image.permute(1, 2, 0).numpy()\n",
    "\n",
    "    # Create figure and axes\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Display the image\n",
    "    ax.imshow(numpy_image)\n",
    "\n",
    "    # Create a Rectangle patch\n",
    "    # Unpack the box coordinates\n",
    "    x_min, y_min, x_max, y_max = box\n",
    "    \n",
    "    rect = patches.Rectangle((x_min, y_min), x_max - x_min, y_max - y_min, linewidth=1, edgecolor='r', facecolor='none')\n",
    "\n",
    "    # Add the patch to the Axes\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "    plt.axis('off')  # Turn off axis numbers\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import v2 as T\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import itertools\n",
    "\n",
    "\n",
    "class CupDataset(Dataset):\n",
    "    def __init__(self, dataframe, root_dir, transforms_2 = None):\n",
    "\n",
    "        self.dataframe = dataframe\n",
    "        self.transforms_2 = transforms_2\n",
    "        self.root_dir = root_dir\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def test_box_permutations(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.dataframe.iloc[idx, 0])\n",
    "        img = cv2.imread(img_name)\n",
    "        image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Get original box from the dataframe\n",
    "        original_box = self.dataframe.iloc[idx, 1]\n",
    "\n",
    "        # Generate all permutations of the box coordinates\n",
    "        for permutation in itertools.permutations(original_box):\n",
    "            # Display the image with the permuted box\n",
    "            self.show_image_with_box(image, permutation)\n",
    "\n",
    "    @staticmethod\n",
    "    def show_image_with_box(image, new_box):\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.imshow(image)\n",
    "\n",
    "        # Unpack the box coordinates\n",
    "        x_min, y_min, x_max, y_max = new_box\n",
    "        rect = patches.Rectangle((x_min, y_min), x_max - x_min, y_max - y_min, linewidth=1, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.dataframe.iloc[idx, 0])\n",
    "        img = cv2.imread(img_name)\n",
    "        if img is None:\n",
    "            raise ValueError(f\"Image not found: {img_name}\")\n",
    "        image = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        orig_height, orig_width = image.shape[:2]\n",
    "\n",
    "        # Scale the image pixel values to [0, 255] if necessary\n",
    "        if image.dtype == np.float32:\n",
    "            image = (image * 255).astype(np.uint8)\n",
    "       \n",
    "        # Get dimensions of the image\n",
    "        orig_height, orig_width = image.shape[:2]\n",
    "\n",
    "        image_id = torch.tensor([idx], dtype=torch.int64)\n",
    "        box = torch.tensor(self.dataframe.iloc[idx, 1], dtype=torch.float32)\n",
    "\n",
    "        y_max, y_min, x_max, x_min = box\n",
    "\n",
    "\n",
    "        scale_x = 224.0 / orig_width\n",
    "        scale_y = 224.0 / orig_height   \n",
    "\n",
    "\n",
    "        # Format the box for model input\n",
    "        new_box = torch.tensor([[x_min * scale_x, y_min * scale_y, x_max * scale_x, y_max * scale_y]], dtype=torch.float32)\n",
    "        labels = torch.ones((1,), dtype=torch.int64)\n",
    "        # area = (new_box[3] - new_box[1]) * (new_box[2] - new_box[0])\n",
    "        # if area <= 0:\n",
    "        #     raise ValueError(f\"Invalid bounding box with negative area: {box}\")\n",
    "\n",
    "        # iscrowd = torch.zeros((new_box.shape[0],), dtype=torch.int64)\n",
    "        \n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "        image = transform(image)\n",
    "        # image = np.array(image)\n",
    "        # print(image)\n",
    "        \n",
    "\n",
    "        # Create target dictionary\n",
    "        target = {}\n",
    "        target[\"boxes\"] = new_box\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"image_id\"] = image_id\n",
    "        # target[\"area\"] = area\n",
    "        # target[\"iscrowd\"] = iscrowd\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "        return image, target\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
